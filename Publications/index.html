<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Home</title><meta name="author" content="Caiyong Wang"><link rel="shortcut icon" href="/img/horse.jpg"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 4.2.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Home</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/Publications"> Publications</a></li><li class="menus_item"><a class="site-page" href="/Research"> Research</a></li><li class="menus_item"><a class="site-page" href="/Database"> Database</a></li><li class="menus_item"><a class="site-page" href="/Resources"> Resources</a></li><li class="menus_item"><a class="site-page" href="/Teaching"> Teaching &amp; Graduate Enrolment</a></li><li class="menus_item"><a class="site-page" href="/Awards"> Awards</a></li><li class="menus_item"><a class="site-page" href="/Activities"> Activities</a></li><li class="menus_item"><a class="site-page" href="/Contact"> Contact</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/wcy.jpg'" alt="avatar"></div><div class="author-discrip"><h3>Caiyong Wang</h3><p class="author-bio">Ph.D., Associate Professor</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-links"><li><a class="e-social-link" href="https://github.com/xiamenwcy" target="_blank"><i class="fab fa-github" aria-hidden="true"></i><span>Github</span></a></li><li><a class="e-social-link" href="https://scholar.google.com/citations?hl=zh-CN&amp;user=eUQw-HgAAAAJ" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="https://orcid.org/0000-0001-7341-3904" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">Publications</h2><article><h1 id="2026"><a href="#2026" class="headerlink" title="2026"></a>2026</h1><ul>
<li><strong>Attention-assisted multilevel fusion framework for generalized iris presentation attack detection</strong><br><strong>Caiyong Wang</strong><sup><i class="far fa-envelope"></i></sup>, Lin Li, Fukang Guo, Haiyu Wang, Zhaofeng He, and Zhenan Sun<br>Pattern Recognition (Volume 171, Article Number: 112262, March 2026)<br><a href="https://www.sciencedirect.com/science/article/pii/S0031320325009239" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/xiamenwcy/AMF-IPAD" target="_blank" rel="noopener">[GitHub]</a></li>
</ul>
<h1 id="2025"><a href="#2025" class="headerlink" title="2025"></a>2025</h1><ul>
<li><p><strong>基于空间域与频域特征融合的虹膜呈现攻击检测</strong><br><strong>王财勇</strong><sup><i class="far fa-envelope"></i></sup>, 孙娴蕴, 李林, 赵光哲, 何召锋, 孙哲南<br>中国图象图形学报(2025, 1-16)<br><a href="https://www.cjig.cn/zh/article/doi/10.11834/jig.240783/" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/XianyunSun/fre-iris-pad" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>基于轻量级卷积神经网络的多模态生物特征识别系统设计</strong><br>刘丰华, 马秋平, 张琪, <strong>王财勇</strong><br>科学技术与工程(2025, 25(11): 4673-4681)<br><a href="http://www.stae.com.cn/jsygc/article/abstract/2404922" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>基于改进浣熊优化算法的多模态生物特征识别</strong><br>刘丰华, 张琪, <strong>王财勇</strong><br>数据与计算发展前沿(2025, 7(1): 56-67)<br><a href="http://www.jfdc.cnic.cn/CN/10.11871/jfdc.issn.2096-742X.2025.01.004" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>TGNF-Net: Two-Stage Geometric Neighborhood Fusion Network for Category-Level 6D Pose Estimation</strong><br>Xiaolong Zhao, Feihu Yan, Guangzhe Zhao, and <strong>Caiyong Wang</strong><br>Information (Volume: 16, Issue: 2, Article Number: 113, 6 February 2025)<br><a href="https://www.mdpi.com/2078-2489/16/2/113" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>SAM-Iris: A SAM-Based Iris Segmentation Algorithm</strong><br>Jian Jiang, Qi Zhang, and <strong>Caiyong Wang</strong><br>Electronics (Volume: 14, Issue: 2, Article Number: 246, 9 January 2025)<br><a href="https://www.mdpi.com/2079-9292/14/2/246" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>IrisFormer: A Dedicated Transformer Framework for Iris Recognition</strong><br>Xianyun Sun, <strong>Caiyong Wang</strong><sup><i class="far fa-envelope"></i></sup>, Yunlong Wang, Jianze Wei, and Zhenan Sun<br>IEEE Signal Processing Letters (vol. 32, pp. 431-435, 2025)<br><a href="https://ieeexplore.ieee.org/document/10816462" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/XianyunSun/IrisFormer" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>An improved hierarchical neural network model with local and global feature matching for script event prediction</strong><br>Pengpeng Zhou, Bin Wu, <strong>Caiyong Wang</strong><sup><i class="far fa-envelope"></i></sup>, and Longzhu He<br>Expert Systems with Applications (Volume: 259, Article Number: 125325, 1 January 2025)<br><a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417424021924" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/xianhuaxizi/Hierarchical-SEP-Model" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
</ul>
<h1 id="2024"><a href="#2024" class="headerlink" title="2024"></a>2024</h1><ul>
<li><p><strong>Sclera-TransFuse: Fusing Vision Transformer and CNN for Accurate Sclera Segmentation and Recognition</strong><br><strong>Caiyong Wang</strong>, Haiqing Li<sup><i class="far fa-envelope"></i></sup>, Yixin Zhang, Guangzhe Zhao, Yunlong Wang, and Zhenan Sun<br>IEEE Transactions on Biometrics, Behavior, and Identity Science (Volume: 6, Issue: 4, pp. 575-590, 17 June 2024)<br><a href="https://ieeexplore.ieee.org/document/10559402" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/lhqqq/Sclera-TransFuse" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>Expression-aware Neural Radiance Fields for High-fidelity Talking Portrait Synthesis</strong><br>Xueping Wang, Tao Ruan, Jun Xu, Xueni Guo, Jiahe Li, Feihu Yan, Guangzhe Zhao, and <strong>Caiyong Wang</strong><br>Image and Vision Computing (Volume: 147, Article Number: 105075, 23 May 2024)<br><a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885624001793" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>OcularSeg: Accurate and Efficient Multi-Modal Ocular Segmentation in Non-Constrained Scenarios</strong><br>Yixin Zhang, <strong>Caiyong Wang</strong><sup><i class="far fa-envelope"></i></sup>, Haiqing Li, Xianyun Sun, Qichuan Tian, and Guangzhe Zhao<br>Electronics (Volume: 13, Issue: 10, Article Number: 1967, 17 May 2024)<br><a href="https://www.mdpi.com/2079-9292/13/10/1967" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/koala0623/OcularSeg" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>异质虹膜识别研究综述</strong><br>孔佳琳, 张琪, <strong>王财勇</strong><br>计算机科学(2024, 51(6): 186-197)<br><a href="https://www.jsjkx.com/CN/10.11896/jsjkx.231200175" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>基于深度学习的虹膜识别研究综述</strong><br>江健, 张琪, <strong>王财勇</strong><br>计算机科学与探索(2024, 18(6): 1421-1437)<br><a href="http://fcst.ceaj.org/CN/10.3778/j.issn.1673-9418.2312062" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>虹膜呈现攻击检测综述</strong><br><strong>王财勇</strong>, 刘星雨, 房美玲, 赵光哲, 何召锋, <strong>孙哲南</strong><sup><i class="far fa-envelope"></i></sup><br>自动化学报(2024, 50(2): 241−281)<br><a href="http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c230109" target="_blank" rel="noopener">[Paper]</a></p>
</li>
</ul>
<h1 id="2023"><a href="#2023" class="headerlink" title="2023"></a>2023</h1><ul>
<li><p><strong>Sclera-TransFuse: Fusing Swin Transformer and CNN for Accurate Sclera Segmentation</strong><br>Haiqing Li, <strong>Caiyong Wang</strong><sup><i class="far fa-envelope"></i></sup>, Guangzhe Zhao, Zhaofeng He, Yunlong Wang, and Zhenan Sun<br>IEEE International Joint Conference on Biometrics (IJCB), Ljubljana, Slovenia, 2023<br><a href="https://ieeexplore.ieee.org/document/10448814" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/lhqqq/Sclera-TransFuse" target="_blank" rel="noopener">[GitHub]</a> [<font color='red'>Best Student Paper Award</font>]</p>
</li>
<li><p><strong>Sclera Segmentation and Joint Recognition Benchmarking Competition: SSRBC 2023</strong><br>Abhijit Das, Saurabh Atreya, Aritra Mukherjee, Matej Vitek, Haiqing Li, <strong>Caiyong Wang</strong>, Guangzhe Zhao, et al.<br>IEEE International Joint Conference on Biometrics (IJCB), Ljubljana, Slovenia, 2023<br><a href="https://ieeexplore.ieee.org/document/10448601" target="_blank" rel="noopener">[Paper]</a> <a href="https://sites.google.com/hyderabad.bits-pilani.ac.in/ssrbc2023/home" target="_blank" rel="noopener">[Website]</a> [<font color='red'>SSRBC 2023 Winner</font>]</p>
</li>
<li><p><strong>Iris Liveness Detection Competition (LivDet-Iris) – The 2023 Edition</strong><br>Patrick Tinsley, Sandip Purnapatra, Mahsa Mitcheff, Aidan Boyd, Colton Crum, Kevin Bowyer, Patrick Flynn, Stephanie Schuckers, Adam Czajka, Meiling Fang, Naser Damer, Xingyu Liu, <strong>Caiyong Wang</strong>, Xianyun Sun, Zhaohua Chang, Xinyue Li, Guangzhe Zhao, et al.<br>IEEE International Joint Conference on Biometrics (IJCB), Ljubljana, Slovenia, 2023<br><a href="https://ieeexplore.ieee.org/document/10448637" target="_blank" rel="noopener">[Paper]</a> <a href="https://livdetiris23.github.io/" target="_blank" rel="noopener">[Website]</a> [<font color='red'>LivDet-Iris 2023 Winner in “ACER2” test protocol</font>]</p>
</li>
<li><p><strong>SynFacePAD 2023: Competition on Face Presentation Attack Detection Based on Privacy-aware Synthetic Training Data</strong><br>Meiling Fang, Marco Huber, Julian Fierrez, Raghavendra Ramachandra, Naser Damer, Alhasan Alkhaddour, Maksim Kasantcev, Vasiliy Pryadchenko, Ziyuan Yang, Huijie Huangfu, Yingyu Chen, Yi Zhang, Yuchen Pan, Junjun Jiang, Xianming Liu, Xianyun Sun, <strong>Caiyong Wang</strong>, Xingyu Liu, Zhaohua Chang, Guangzhe Zhao, et al.<br>IEEE International Joint Conference on Biometrics (IJCB), Ljubljana, Slovenia, 2023<br><a href="https://ieeexplore.ieee.org/document/10449130" target="_blank" rel="noopener">[Paper]</a> <a href="https://sites.google.com/view/ijcb-synfacepad-2023" target="_blank" rel="noopener">[Website]</a> [<font color='red'>Ranked 4th</font>]</p>
</li>
<li><p><strong>DFGC-VRA: DeepFake Game Competition on Visual Realism Assessment</strong><br>Bo Peng, Xianyun Sun, <strong>Caiyong Wang</strong>, Wei Wang, Jing Dong, Zhenan Sun, et al.<br>IEEE International Joint Conference on Biometrics (IJCB), Ljubljana, Slovenia, 2023<br><a href="https://ieeexplore.ieee.org/document/10448757" target="_blank" rel="noopener">[Paper]</a> <a href="https://codalab.lisn.upsaclay.fr/competitions/10754" target="_blank" rel="noopener">[Website]</a></p>
</li>
<li><p><strong>Visual Realism Assessment for Face-swap Videos</strong><br>Xianyun Sun, Beibei Dong, <strong>Caiyong Wang</strong>, Bo Peng, and Jing Dong<br>International Conference on Image and Graphics (ICIG), Nanjing, China, 2023<br><a href="https://link.springer.com/chapter/10.1007/978-3-031-46305-1_34" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/XianyunSun/VRA.git" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>MetaScleraSeg: an effective meta-learning framework for generalized sclera segmentation</strong><br><strong>Caiyong Wang</strong>, Haiqing Li, Wenhui Ma, Guangzhe Zhao, and Zhaofeng He<br>Neural Computing and Applications (Volume: 35, Issue: 29, pp: 21797–21826, 21 August 2023)<br><a href="https://link.springer.com/article/10.1007/s00521-023-08937-8" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/lhqqq/MetaScleraSeg" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>IrisGuideNet: Guided Localization and Segmentation Network for Unconstrained Iris Biometrics</strong><br>Jawad Muhammad, <strong>Caiyong Wang</strong>, Yunlong Wang, Kunbo Zhang, Zhenan Sun<br>IEEE Transactions on Information Forensics and Security (IEEE T-IFS) ( Volume: 18, pp: 2723-2736, 19 April 2023 )<br><a href="https://ieeexplore.ieee.org/document/10105641" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/mohdjawadi/IrisGuidenet" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>Exploring Bias in Sclera Segmentation Models: A Group Evaluation Approach</strong><br>Matej Vitek, Abhijit Das, Diego Rafael Lucio, Luiz Antonio Zanlorensi, David Menotti, Jalil Nourmohammadi Khiarak, Mohsen Akbari Shahpar, Meysam Asgari-Chenaghlu, Farhang Jaryani, Juan E. Tapia, Andres Valenzuela, <strong>Caiyong Wang</strong>, Yunlong Wang, Zhaofeng He, Zhenan Sun, Fadi Boutros, Naser Damer, Jonas Henry Grebe, Arjan Kuijper, Kiran Raja, Gourav Gupta, Georgios Zampoukis, Lazaros Tsochatzidis, Ioannis Pratikakis, S. V. Aruna Kumar, B. S. Harish, Umapada Pal, Peter Peer and Vitomir Štruc<br>IEEE Transactions on Information Forensics and Security (IEEE T-IFS) (Volume: 18, pp. 190-205, 2023)<br><a href="https://ieeexplore.ieee.org/document/9926136" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/MatejVitek/GE" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>多层次特征融合和注意力机制的道路裂缝模型</strong><br>宋榕榕, <strong>王财勇</strong><sup><i class="far fa-envelope"></i></sup>, 田启川, 张琪<br>计算机工程与应用(2023, 59(13): 281-288)<br><a href="http://cea.ceaj.org/CN/10.3778/j.issn.1002-8331.2203-0531" target="_blank" rel="noopener">[Paper]</a></p>
</li>
</ul>
<h1 id="2022"><a href="#2022" class="headerlink" title="2022"></a>2022</h1><ul>
<li><p><strong>D-ESRGAN: A Dual-Encoder GAN with Residual CNN and Vision Transformer for Iris Image Super-Resolution</strong><br><strong>Caiyong Wang</strong>, Tianhao Lu, Gaosheng Wu, Yunlong Wang, and Zhenan Sun<br>IEEE International Joint Conference on Biometrics (IJCB), Abu Dhabi, United Arab Emirates, 2022<br><a href="https://ieeexplore.ieee.org/document/10007938" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>Generating Intra- and Inter-Class Iris Images by Identity Contrast</strong><br>Chen Wang, Zhaofeng He, <strong>Caiyong Wang</strong>, and Qing Tian<br>IEEE International Joint Conference on Biometrics (IJCB), Abu Dhabi, United Arab Emirates, 2022<br><a href="https://ieeexplore.ieee.org/document/10007974" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/chenwang2022/iris-generation" target="_blank" rel="noopener">[GitHub]</a> </p>
</li>
<li><p><strong>结合Transformer与对称型编解码器的噪声虹膜图像分割方法</strong><br>顾正杰, <strong>王财勇</strong><sup><i class="far fa-envelope"></i></sup>, 田启川, 张琪<br>计算机辅助设计与图形学学报(2022, 34(12): 1887-1898)<br><a href="https://www.jcad.cn/cn/article/doi/10.3724/SP.J.1089.2022.19235" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>What happens next? Combining enhanced multilevel script learning and dual fusion strategies for script event prediction</strong><br>Pengpeng Zhou, Bin Wu, <strong>Caiyong Wang</strong>, Hao Peng, Juwei Yue, and Song Xiao<br>International Journal of Intelligent Systems (IJIS) ( Volume: 37, Issue: 11, pp: 10001-10040, 03 September 2022 )<br><a href="https://onlinelibrary.wiley.com/doi/10.1002/int.23025" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/xianhuaxizi/EMDF-Net" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>Multitask deep active contour-based iris segmentation for off-angle iris images</strong><br>Tianhao Lu, <strong>Caiyong Wang</strong><sup><i class="far fa-envelope"></i></sup>, Yunlong Wang, and Zhenan Sun<sup><i class="far fa-envelope"></i></sup><br>Journal of Electronic Imaging ( Volume: 31, Issue: 4, pp: 041211(1-21), 26 February 2022 )<br><a href="https://doi.org/10.1117/1.JEI.31.4.041211" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/lutianhao/IrisGazeSeg" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>基于关键点的眼睛定位和状态估计</strong><br>何勇, 孙哲南, <strong>王财勇</strong>, 王云龙, 朱宇豪<br>计算机应用与软件(2022, 39(04): 185-192)<br><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2022&filename=JYRJ202204029&uniplatform=NZKPT&v=Ik-EGuNOCdZmVpb6PiDWGWbI2gE6b3Jwd96F5wORyLWAajeJDj_a27L-Bxyk56Vm" target="_blank" rel="noopener">[Paper]</a></p>
</li>
</ul>
<h1 id="2021"><a href="#2021" class="headerlink" title="2021"></a>2021</h1><ul>
<li><p><strong>NIR Iris Challenge Evaluation in Non-cooperative Environments: Segmentation and Localization</strong><br><strong>Caiyong Wang</strong>, Yunlong Wang, Kunbo Zhang, Jawad Muhammad, Tianhao Lu, Qi Zhang, Qichuan Tian, Zhaofeng He, Zhenan Sun, et al.<br>IEEE International Joint Conference on Biometrics (IJCB), Shenzhen, China, 2021<br><a href="https://ieeexplore.ieee.org/document/9484336" target="_blank" rel="noopener">[Paper]</a> <a href="/Publications/files/0198_supp.pdf">[Supplementary Material]</a> <a href="https://sites.google.com/view/nir-isl2021/home" target="_blank" rel="noopener">[Website]</a> <a href="https://github.com/xiamenwcy/NIR-ISL-2021" target="_blank" rel="noopener">[GitHub]</a> <a href="https://arxiv.org/pdf/2109.00162.pdf" target="_blank" rel="noopener">[An interesting application]</a> </p>
</li>
<li><p><strong>CASIA-Face-Africa: A Large-scale African Face Image Database</strong><br>Jawad Muhammad, Yunlong Wang, <strong>Caiyong Wang</strong>, Kunbo Zhang, Zhenan Sun<br>IEEE Transactions on Information Forensics and Security (IEEE T-IFS) ( Volume: 16, pp: 3634-3646, 16 June 2021 )<br><a href="https://ieeexplore.ieee.org/document/9456939" target="_blank" rel="noopener">[Paper]</a> <a href="http://www.cripacsir.cn/dataset/casia-face-africa/" target="_blank" rel="noopener">[Dataset]</a></p>
</li>
<li><p><strong>Deep learning super-resolution electron microscopy based on deep residual attention network</strong><br>Jia Wang, Chuwen Lan, <strong>Caiyong Wang</strong>, Zehua Gao<br>International Journal of Imaging Systems and Technology ( Volume: 31, Issue: 4, pp: 2158-2169, December 2021 )<br><a href="https://onlinelibrary.wiley.com/doi/10.1002/ima.22588" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/wangjia0602/DRAN" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
</ul>
<h1 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h1><ul>
<li><p><strong>SSBC 2020: Sclera Segmentation Benchmarking Competition in the Mobile Environment</strong><br>Matej Vitek, ABHIJIT DAS, Yann Pourcenoux, Alexandre Missler, Calvin Paumier, Sumanta Das, Ishita De Ghosh, Diego R. Lucio, Luiz Zanlorensi, David Menotti, Fadi Boutros, Naser Damer, Jonas Henry Grebe, Arjan Kuijper, Junxing Hu, yong he, <strong>Caiyong Wang</strong>, Hongda Liu, Yunlong Wang, Zhenan Sun, Daile Osorio, Christian Rathgeb, Christoph Busch, Juan Tapia Farias, Andres Valenzuela, Georgios Zampoukis, Lazaros Tsochatzidis, Ioannis Pratikakis, sabari nathan, Suganya R, Vineet Mehta, Abhinav Dhall, Kiran Raja, Gourav Gupta, Jalil Nourmohammadi Khiarak, Mohsen Akbari-Shahper, Farhang Jaryani, Meysam Asgari-Chenaghlu, Ritesh Vyas, Sristi Dakshit, Sagnik Dakshit, Peter Peer, Umapada Pal  and Vitomir Struc<br>IEEE International Joint Conference on Biometrics (IJCB), Online, Houston, USA, 2020<br><a href="https://ieeexplore.ieee.org/document/9304881" target="_blank" rel="noopener">[Paper]</a> <a href="https://sites.google.com/view/ssbc2020/home" target="_blank" rel="noopener">[Website]</a> </p>
</li>
<li><p><strong>Towards Complete and Accurate Iris Segmentation Using Deep Multi-Task Attention Network for Non-Cooperative Iris Recognition</strong><br><strong>Caiyong Wang</strong>, Jawad Muhammad, Yunlong Wang, Zhaofeng He, Zhenan Sun<sup><i class="far fa-envelope"></i></sup><br>IEEE Transactions on Information Forensics and Security ( Volume: 15, Issue: 1, pp: 2944-2959, Apr. 2020 )<br><a href="https://ieeexplore.ieee.org/document/9036930" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/xiamenwcy/IrisParseNet" target="_blank" rel="noopener">[GitHub]</a> [for Prof. Hugo Proença’s <a href="https://ieeexplore.ieee.org/abstract/document/9916508" target="_blank" rel="noopener">DeepGabor</a>] <a href="https://link.springer.com/article/10.1007/s10489-022-03973-8" target="_blank" rel="noopener">[follow-up work1]</a> <a href="https://doi.org/10.1117/1.JEI.31.5.053035" target="_blank" rel="noopener">[follow-up work2]</a> <a href="https://ieeexplore.ieee.org/document/10007944" target="_blank" rel="noopener">[follow-up work3]</a><br><a href="https://link.springer.com/article/10.1007/s00530-024-01280-5" target="_blank" rel="noopener">[follow-up work4]</a> <a href="https://ieeexplore.ieee.org/document/10105641" target="_blank" rel="noopener">[follow-up work5]</a> <a href="https://ieeexplore.ieee.org/document/10030850" target="_blank" rel="noopener">[follow-up work6]</a> <a href="https://doi.org/10.1117/1.JEI.31.4.041211" target="_blank" rel="noopener">[follow-up work7]</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865521003743" target="_blank" rel="noopener">[follow-up work8]</a> <a href="https://link.springer.com/article/10.1007/s10489-024-05862-8" target="_blank" rel="noopener">[follow-up work9]</a><br><a href="https://www.sciencedirect.com/science/article/abs/pii/S1568494625003205" target="_blank" rel="noopener">[follow-up work10]</a> <a href="https://www.sciencedirect.com/science/article/pii/S1568494625006453" target="_blank" rel="noopener">[follow-up work11]</a> </p>
</li>
<li><p><strong>A Lightweight Multi-Label Segmentation Network for Mobile Iris Biometrics</strong><br><strong>Caiyong Wang</strong>, Yunlong Wang, Boqiang Xu, Yong He, Zhiwei Dong, Zhenan Sun<sup><i class="far fa-envelope"></i></sup><br>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 2020<br><a href="https://ieeexplore.ieee.org/document/9054353" target="_blank" rel="noopener">[Paper]</a></p>
</li>
<li><p><strong>ScleraSegNet: An Attention Assisted U-Net Model for Accurate Sclera Segmentation</strong><br><strong>Caiyong Wang</strong>, Yunlong Wang, Yunfan Liu, Zhaofeng He, Ran He, Zhenan Sun<sup><i class="far fa-envelope"></i></sup><br>IEEE Transactions on Biometrics, Behavior, and Identity Science ( Volume: 2, Issue: 1, pp: 40-54, Jan. 2020 )<br><a href="https://ieeexplore.ieee.org/document/8944028" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/xiamenwcy/ScleraSegNet" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
<li><p><strong>A Benchmark for Iris Segmentation</strong><br><strong>Caiyong Wang</strong>, Zhenan Sun<sup><i class="far fa-envelope"></i></sup><br>Journal of Computer Research and Development [<font color='red'>in Chinese</font>] ( Volume: 57, Issue: 2, pp: 395-412, Feb. 2020 )<br><a href="http://crad.ict.ac.cn/CN/10.7544/issn1000-1239.2020.20190092" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/xiamenwcy/IrisSegBenchmark" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
</ul>
<h1 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h1><ul>
<li><p><strong>ScleraSegNet: an Improved U-Net Model with Attention for Accurate Sclera Segmentation</strong><br><strong>Caiyong Wang</strong>, Yong He, Yunfan Liu, Zhaofeng He, Ran He, Zhenan Sun<sup><i class="far fa-envelope"></i></sup><br>International Conference on Biometrics (ICB), Crete, Greece, 2019<br><a href="https://ieeexplore.ieee.org/document/8987270" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/xiamenwcy/ScleraSegNet" target="_blank" rel="noopener">[GitHub]</a> [<font color='red'>Honorable Mention Paper Award</font>]</p>
</li>
<li><p><strong>Sclera Segmentation Benchmarking Competition in Cross-resolution Environment</strong><br>Abhijit Das, Umapada Pal, Michael Blumenstein, <strong>Caiyong Wang</strong>, Yong He, Yuhao Zhu, Zhenan Sun<br>International Conference on Biometrics (ICB), Crete, Greece, 2019<br><a href="https://ieeexplore.ieee.org/document/8987414" target="_blank" rel="noopener">[Paper]</a> <a href="https://sites.google.com/view/ssbc2019/home" target="_blank" rel="noopener">[Website]</a> [<font color='red'>SSBC 2019 Winner</font>]</p>
</li>
<li><p><strong>Alignment Free and Distortion Robust Iris Recognition</strong><br>Min Ren, <strong>Caiyong Wang</strong>, Yunlong Wang, Zhenan Sun<sup><i class="far fa-envelope"></i></sup>, Tieniu Tan<br>International Conference on Biometrics (ICB), Crete, Greece, 2019<br><a href="https://ieeexplore.ieee.org/document/8987369" target="_blank" rel="noopener">[Paper]</a> <a href="https://arxiv.org/abs/1912.00382" target="_blank" rel="noopener">[arXiv]</a> </p>
</li>
<li><p><strong>Joint Iris Segmentation and Localization Using Deep Multi-task Learning Framework</strong><br><strong>Caiyong Wang</strong>, Yuhao Zhu, Yunfan Liu, Ran He, Zhenan Sun<sup><i class="far fa-envelope"></i></sup><br>arXiv preprint arXiv:1901.11195<br><a href="https://arxiv.org/abs/1901.11195" target="_blank" rel="noopener">[arXiv]</a> <a href="https://github.com/xiamenwcy/IrisParseNet" target="_blank" rel="noopener">[GitHub]</a></p>
</li>
</ul>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/Publications"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/Research"> Research</a></li><li class="nav_item"><a class="nav-page" href="/Database"> Database</a></li><li class="nav_item"><a class="nav-page" href="/Resources"> Resources</a></li><li class="nav_item"><a class="nav-page" href="/Teaching"> Teaching &amp; Graduate Enrolment</a></li><li class="nav_item"><a class="nav-page" href="/Awards"> Awards</a></li><li class="nav_item"><a class="nav-page" href="/Activities"> Activities</a></li><li class="nav_item"><a class="nav-page" href="/Contact"> Contact</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2025 by Caiyong Wang</div><div class="theme-info">Powered by <a href="https://hexo.io" target="_blank" rel="nofollow noopener">Hexo</a> & <a href="https://github.com/PhosphorW/hexo-theme-academia" target="_blank" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>