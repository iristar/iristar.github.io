<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Home</title><meta name="author" content="Caiyong Wang"><link rel="shortcut icon" href="/img/horse.jpg"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 4.2.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Home</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/Publications"> Publications</a></li><li class="menus_item"><a class="site-page" href="/Research"> Research</a></li><li class="menus_item"><a class="site-page" href="/Database"> Database</a></li><li class="menus_item"><a class="site-page" href="/Resources"> Resources</a></li><li class="menus_item"><a class="site-page" href="/Awards"> Awards</a></li><li class="menus_item"><a class="site-page" href="/Activities"> Activities</a></li><li class="menus_item"><a class="site-page" href="/Contact"> Contact</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/wcy.jpg'" alt="avatar"></div><div class="author-discrip"><h3>Caiyong Wang</h3><p class="author-bio">Ph.D., Lecturer</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-links"><li><a class="e-social-link" href="https://github.com/xiamenwcy" target="_blank"><i class="fab fa-github" aria-hidden="true"></i><span>Github</span></a></li><li><a class="e-social-link" href="https://scholar.google.com/citations?hl=zh-CN&amp;user=eUQw-HgAAAAJ" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="https://orcid.org/0000-0001-7341-3904" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">home</h2><article><h1 id="About-Me"><a href="#About-Me" class="headerlink" title="About Me"></a>About Me</h1><p>Caiyong Wang is currently a Lecturer and Master’s Supervisor with the School of Electrical and Information Engineering, <a href="http://www.bucea.edu.cn/" target="_blank" rel="noopener">Beijing University of Civil Engineering and Architecture</a>, China. He successfully received the Ph.D. degree in Pattern Recognition and Intelligent Systems from <a href="http://www.ia.cas.cn/" target="_blank" rel="noopener">Institute of Automation, Chinese Academy of Sciences (CASIA)</a>, China, in 2020 (supervised by Prof. <a href="http://www.cbsr.ia.ac.cn/users/znsun/" target="_blank" rel="noopener">Zhenan Sun</a>). Prior to his PhD, he has worked as an Algorithm Engineer at <a href="http://www.lusterinc.com/" target="_blank" rel="noopener">LUSTER LightTech Group</a> and <a href="https://www.cmcm.com/" target="_blank" rel="noopener">Cheetah Mobile</a>. He received the B.E. degree in applied mathematics from <a href="http://www.xju.edu.cn/" target="_blank" rel="noopener">Xinjiang University</a>, China, in 2013, and the M.S. degree in computational mathematics from <a href="https://www.xmu.edu.cn/" target="_blank" rel="noopener">Xiamen University</a>, China, in 2016. His research interests include biometrics, computer vision, and deep learning. He has received an Honorable Mention Paper Award at ICB 2019. He is also the winner of <a href="https://sites.google.com/view/ssbc2019/home" target="_blank" rel="noopener">Sclera Segmentation Benchmarking Competition (SSBC) 2019</a>. He is currently focusing on <strong>Ocular Biometrics (including iris, sclera, and periocular)</strong> and devoting to improve the performance of ocular preprocessing and feature analysis using advanced deep learning and pattern recognition technologies.</p>
<h1 id="News"><a href="#News" class="headerlink" title="News"></a>News</h1><ul>
<li><p>2022.08：Our co-authored paper has been accepted by <em><a href="https://onlinelibrary.wiley.com/journal/1098111x" target="_blank" rel="noopener">International Journal of Intelligent Systems</a> (<strong>SCI-Indexed, CCF-C, Impact factor (2021):8.993</strong>)</em>. Congratulations to Dr. Pengpeng Zhou!    </p>
</li>
<li><p>2022.07：Two papers are accepted by <a href="http://ijcb2022.org/#/" target="_blank" rel="noopener">The 2022 International Joint Conference on Biometrics (IJCB 2022)</a>.</p>
</li>
<li><p>2022.02：Our co-authored paper entitled as “<a href="https://doi.org/10.1117/1.JEI.31.4.041211" target="_blank" rel="noopener">Multitask deep active contour-based iris segmentation for off-angle iris images</a>“ has been published online by <em>Journal of Electronic Imaging (<strong>SCI-Indexed</strong>)</em>. Congratulations to Tianhao Lu!    </p>
</li>
<li><p>2021.08：Good news! I got the funding from the National Natural Science Foundation of China (NSFC for Youths) in the future three years (2022.01-2024.12).    </p>
</li>
<li><p>2021.06：The summary paper of <a href="https://sites.google.com/view/nir-isl2021/home" target="_blank" rel="noopener"><strong>NIR-ISL 2021</strong></a> has been accepted by <a href="http://ijcb2021.iapr-tc4.org/" target="_blank" rel="noopener">IJCB 2021</a>! </p>
</li>
<li><p>2021.05：Results of our held IJCB 2021 Official Competition (<strong>NIR-ISL 2021</strong>) have been announced via <a href="https://sites.google.com/view/nir-isl2021/home" target="_blank" rel="noopener">https://sites.google.com/view/nir-isl2021/home</a>. Congratulations to top-3 winning teams!   </p>
</li>
<li><p>2021.05：Our co-authored paper entitled as “CASIA-Face-Africa: A Large-scale African Face Image Database” has been accepted by <em>IEEE Transactions on Information Forensics and Security (IEEE T-IFS)</em>. Congratulations to Dr. Jawad Muhammad!</p>
</li>
<li><p>2021.05：Our co-authored paper entitled as “<a href="http://doi.org/10.1002/ima.22588" target="_blank" rel="noopener">Deep learning super-resolution electron microscopy based on deep residual attention network</a>“ has been published online by <em>International Journal of Imaging Systems and Technology (IMA,<strong>SCI-Indexed</strong>)</em>. Congratulations to Jia Wang!</p>
</li>
<li><p>2021.02：Call for participating in the <a href="http://ijcb2021.iapr-tc4.org/competitions/" target="_blank" rel="noopener"><strong>IJCB 2021 Official Competition</strong></a> about <strong>NIR Iris Challenge Evaluation in Non-cooperative Environments: Segmentation and Localization (NIR-ISL 2021)</strong>, welcome to visit our competition website: <a href="https://sites.google.com/view/nir-isl2021/home" target="_blank" rel="noopener">https://sites.google.com/view/nir-isl2021/home</a>. </p>
</li>
<li><p>2020.10：Our group received the <strong>Best Paper Award Runner-Up</strong> at IJCB 2020 for paper titled “All-in-Focus Iris Camera With a Great Capture Volume”. <a href="https://drive.google.com/file/d/1FKILwQrAgrGjyEsBhiEx9i2Fmml-DOrX/view" target="_blank" rel="noopener">This paper</a> introduces a novel long-range and large-volume iris imaging system, which may boost the development of unstrained iris recognition. Congratulations to Dr. Kunbo Zhang!</p>
</li>
<li><p>2020.09: The code of our group’s AAAI paper <a href="https://arxiv.org/abs/1912.00377v2" target="_blank" rel="noopener">《Dynamic Graph Representation for Occlusion Handling in Biometrics》</a> is open at : <a href="https://github.com/RenMin1991/Dyamic_Graph_Representation" target="_blank" rel="noopener">https://github.com/RenMin1991/Dyamic_Graph_Representation</a>. Welcome to fork it! Congratulations to Dr. Min Ren!</p>
</li>
<li><p>2020.09: Our lab website termed as <a href="http://www.cripacsir.cn/" target="_blank" rel="noopener">“SIR-Smart Iris Recognition”</a> is open. We will remain <strong>open-sourced</strong> and <strong>open-minded</strong>, working with researchers around the world with the focus on <strong>ocular biometrics</strong> to advance this area, and welcome to visit it.</p>
</li>
<li><p>2020.03: One paper is accepted by <a href="https://ieeexplore.ieee.org/document/9036930" target="_blank" rel="noopener">IEEE T-IFS</a>.</p>
</li>
<li><p>2020.01: One paper is accepted by <a href="https://ieeexplore.ieee.org/document/9054353" target="_blank" rel="noopener">ICASSP 2020</a>, <strong>oral</strong>.</p>
</li>
</ul>
<h1 id="Call-for-paper"><a href="#Call-for-paper" class="headerlink" title="Call for paper"></a>Call for paper</h1><ul>
<li><p><strong>Pattern Recognition Letters</strong> Special Issue on <a href="https://www.journals.elsevier.com/pattern-recognition-letters/call-for-papers/mobile-and-wearable-biometrics-vsimwb" target="_blank" rel="noopener">Mobile and Wearable Biometrics (VSI:MWB)</a>. Submission Period: <strong>September 1-20, 2021</strong></p>
</li>
<li><p><strong>Pattern Recognition</strong> Special issue on <a href="https://www.journals.elsevier.com/pattern-recognition/call-for-papers/masked-face-recognition-and-touchless-biometrics" target="_blank" rel="noopener">Masked Face Recognition and Touchless Biometrics at the time of COVID-19</a>. Submission Deadline: <strong>November 30th, 2020</strong>.</p>
</li>
<li><p><strong>IET Biometrics</strong> Special issue on <a href="https://www.micc.unifi.it/icpr2020/index.php/iet-biometrics/" target="_blank" rel="noopener">Real-Time Visual Surveillance as-a-Service (VSaaS) for Smart Security Solutions</a>. Submission Deadline: <strong>March 15, 2021</strong>.</p>
</li>
<li><p>The Special Issue on <strong>IEEE Transactions on Biometrics, Behavior and Identity Science (IEEE T-BIOM)</strong> will host extended versions of solid articles shortlisted from accepted <a href="https://www.micc.unifi.it/icpr2020/index.php/ieee-tbiom/" target="_blank" rel="noopener">ICPR 2020</a> papers matching the topics of the Track 2 (<strong>Biometrics, Human Analysis and Behavior Understanding</strong>). Submission Deadline: <strong>January 31, 2021</strong></p>
</li>
<li><p><strong>Pattern Recognition Letters</strong> Special Issue on <a href="https://www.journals.elsevier.com/pattern-recognition-letters/call-for-papers/biometric-presentation-attacks" target="_blank" rel="noopener">Biometric Presentation Attacks: handcrafted features versus deep learning approaches</a>. Submission Period: <strong>October 1st - October 31, 2020</strong></p>
</li>
<li><p><strong>Pattern Recognition Letters</strong> Special Issue on <a href="https://www.journals.elsevier.com/pattern-recognition-letters/call-for-papers/implicit-biometric-authentication" target="_blank" rel="noopener">Implicit Biometric Authentication and Monitoring through Internet of Things</a>. Submission Period: <strong>September 1st -  September 30th, 2020</strong></p>
</li>
<li><p><strong>The 2020 International Joint Conference on Biometrics (IJCB 2020)</strong> calls for papers in <a href="https://ieee-biometrics.org/ijcb2020/index.html" target="_blank" rel="noopener">second round submission</a>. Deadline: <strong>June 8, 2020</strong>.</p>
</li>
<li><p><strong>Pattern Recognition Letters</strong> Virtual Special Issue on <a href="https://www.journals.elsevier.com/pattern-recognition-letters/call-for-papers/virtual-special-issue-biometrics-in-smart-cities" target="_blank" rel="noopener">Biometrics in Smart Cities: Techniques and Applications</a>. First submission paper due: <strong>April 26 – May 20, 2020</strong></p>
</li>
</ul>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/Publications"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/Research"> Research</a></li><li class="nav_item"><a class="nav-page" href="/Database"> Database</a></li><li class="nav_item"><a class="nav-page" href="/Resources"> Resources</a></li><li class="nav_item"><a class="nav-page" href="/Awards"> Awards</a></li><li class="nav_item"><a class="nav-page" href="/Activities"> Activities</a></li><li class="nav_item"><a class="nav-page" href="/Contact"> Contact</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2022 by Caiyong Wang</div><div class="theme-info">Powered by <a href="https://hexo.io" target="_blank" rel="nofollow noopener">Hexo</a> & <a href="https://github.com/PhosphorW/hexo-theme-academia" target="_blank" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>